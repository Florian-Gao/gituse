{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树(Decision Tree)是有监督学习中的一种算法，并且是一种基本的分类与回归的方法。也就是说，决策树有 两种:分类树和回归树。\n",
    "\n",
    "这里我们主要讨论分类树，后面再为大家讲解回归树。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 节点 | 说明 |           \n",
    "|：--：|：--：|              \n",
    "| 根结点 |没进边，有出边 |                       \n",
    "| 中间节点 | 有进有出，进只有一个，出有很多 |                \n",
    "| 叶节点 | 只有进，没有出。每个叶节点都是哟个类别标签 |              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树构建\n",
    "- 1.特征选择\n",
    "- 2.决策树生成\n",
    "- 3.决策树剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一.决策树的构建准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1香农熵及计算函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 纯度（purity）\n",
    "随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能属于同一类别，也就是节点的纯度(purity)越来越高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵定义为信息的期望值。在信息论与概率统计中，熵是表示随机变量不确定性的度量。                                       \n",
    "假定当前样本集合D中一共有n类样本，第i类样本为 $x_i$，那么<font color='red'>$x_i$的信息</font>定义为:                 \n",
    " $l(x_i)=-log_2p(x_i)$             \n",
    "其中$p(x_i)$是选择该分类的概率。<font color='red'>概率越大，$l(x_i)$越小，始终为正，概率达到1，$l(x_i)$为0 概率为0时，$l(x_i)$为无穷大</font>                \n",
    "为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值(数学期望)，通过下面的公式得到:             \n",
    "$Ent(D)=-\\sum_{i=1}^n p(x_i)log_2p(x_i)$       \n",
    "<font color='red'>$Ent(D)$的值越小，则D的不纯度就越低</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 香农熵的python代码如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "函数功能:\n",
    "    计算香农熵\n",
    "参数说明:\n",
    "    dataSet:原始数据集 返回:\n",
    "ent:\n",
    "    香农熵的值 \n",
    "\"\"\"\n",
    "def calEnt(dataSet):\n",
    "    n = dataSet.shape[0]                        #数据集总行数\n",
    "    iset = dataSet.iloc[:,-1].value_counts()    #标签的所有类别\n",
    "    p = iset/n                                  #每一类标签所占比\n",
    "    #sum求和，mean求平均值\n",
    "    ent = (-p*np.log2(p)).sum()                 #计算信息熵\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #创建数据集\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "def createDataSet():\n",
    "    #先建一个字典\n",
    "    row_data = {'no surfacing':[1,1,1,0,0],\n",
    "                'flippers':[1,1,0,1,1],\n",
    "                'fish':['yes','yes','no','no','no']}\n",
    "    #字典转结构\n",
    "    dataSet = pd.DataFrame(row_data)\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish\n",
       "0             1         1  yes\n",
       "1             1         1  yes\n",
       "2             1         0   no\n",
       "3             0         1   no\n",
       "4             0         1   no"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = createDataSet()\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calEnt(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>熵越高，信息的不纯度就越高。也就是混合的数据就越多。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益(Information Gain)的计算公式其实就是父节点的信息熵与其下所有子节点总信息熵之差。但这里要注意的是，此时计算子节点的总信息熵不能简单求和，而要求在求和汇总之前进行修正。\n",
    "假设离散属性a有V个可能的取值${a_1,a_2,a_3....a_n}$,若使用a对样本数据集D进行划分，则会产生V个分支节点， 其中第v个分支节点包含了D中所有在属性a上取值为$a^v$的样本，记为$D^V$.\n",
    "我们可根据信息熵的计算公式计算出$D^v$的信息熵，再考虑到不同的分支节点所包含的样本数不同，给分支节点赋予权重$/frac{|D^v|}{D}$,这就是所谓的的修正。           \n",
    "所以信息增益的计算公式为            \n",
    "$Gain(D,a)=Ent(D)-\\sum_{v=1}^V \\frac{|D^v|}{D}Ent(D^v)$        \n",
    "那我们手动计算一下，海洋生物数据集中第0列的信息增益:       \n",
    "$\\begin{align*} \n",
    "Gain('no surfacing')&=Ent(D)-[\\frac{3}{5}Ent(D_1)+\\frac{2}{5}Ent(D_2)]                                        \n",
    "&=calEnt(dataSet)-[\\frac{3}{5}(-\\frac{2}{3}log_{2}\\frac{2}{3}-\\frac{1}{3}log_{2}\\frac{1}{3})+\\frac{2}{5}(-\\frac{2}{2}log_{2}\\frac{2}{2})]\n",
    "&=0.97-0.55\n",
    "&=0.42\n",
    "\\end{align*}$            \n",
    "同样的方法，把第一列的信息增益算出来为0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据集最佳切分函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='red'>划分数据集的最大准则是选择最大信息增益，也就是信息下降最快的方向。</font>\n",
    "上面这就话就说明这个特征就正好适用于分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:根据信息增益选择出最佳数据集切分的列\n",
    "参数说明:\n",
    "dataSet:原始数据集 返回:\n",
    "axis:数据集最佳切分列的索引 \"\"\"\n",
    "#选择最优的列进行切分\n",
    "def bestSplit(dataSet):\n",
    "    baseEnt = calEnt(dataSet) #计算原始熵\n",
    "    bestGain = 0 #初始化信息增益 \n",
    "    axis = -1 #初始化最佳切分列，标签列 \n",
    "    for i in range(dataSet.shape[1]-1):#对特征的每一列进行循环\n",
    "        levels= dataSet.iloc[:,i].value_counts().index #提取出当前列的所有取值\n",
    "        #print(levels)\n",
    "        ents = 0 #初始化子节点的信息熵 \n",
    "        for j in levels:#对当前列的每一个取值进行循环 \n",
    "            childSet = dataSet[dataSet.iloc[:,i]==j]#某一个子节点的dataframe \n",
    "            ent = calEnt(childSet)#计算某一个子节点的信息熵 \n",
    "            ents += (childSet.shape[0]/dataSet.shape[0])*ent#计算当前列的信息熵\n",
    "        #print(f'第{i}列的信息熵为{ents}')\n",
    "        infoGain = baseEnt-ents #计算当前列的信息增益\n",
    "        #print(f'第{i}列的信息增益为{infoGain}') \n",
    "        if (infoGain > bestGain):\n",
    "            bestGain = infoGain#选择最大信息增益\n",
    "            axis = i #最大信息增益所在列的索引\n",
    "        return axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面手动计算，我们知道: 第0列的信息增益为0.42，第1列的信息增益为0.17，0.42>0.17，所以我们应该选择第0列进行切分数据集。 接下来，我们来验证我们构造的数据集最佳切分函数返回的结果与手动计算的结果是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " bestSplit(dataSet) #返回的结果为0，即选择第0列来切分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.按照给定列切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能:按照给定的列划分数据集\n",
    "参数说明:\n",
    "    dataSet:原始数据集 \n",
    "    axis:指定的列索引 \n",
    "    value:指定的属性值\n",
    "返回: redataSet:按照指定列索引和属性值切分后的数据集\n",
    "\"\"\"\n",
    "def mySplit(dataSet,axis,value):\n",
    "    col = dataSet.columns[axis]\n",
    "    redataSet = dataSet.loc[dataSet[col]==value,:].drop(col,axis=1)\n",
    "    return redataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证函数，以axis=0，value=1为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flippers fish\n",
       "0         1  yes\n",
       "1         1  yes\n",
       "2         0   no"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySplit(dataSet,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二，递归构建决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前我们已经学习了从数据集构造决策树算法所需要的子功能模块，其工作原理如下：<font color='red'>得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分。第一次划分之后，数据集被向下传递到树的分支的下一个结点。在这个结点上，我们可以再次划分数据。因此我们可以采用递归的原则处理数据集。</font>               \n",
    "决策树生成算法递归地产生决策树，直到不能继续下去未为止。这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。<font color='green'>过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。</font>解决这个问题的办法是考虑决策树的复杂度，对已生成的决策树进行简化，也就是常说的剪枝处理。剪枝处理的具体讲解我会放在回归树里面。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>ID3算法的核心是在决策树各个节点上对应信息增益准则选择特征，递归地构建决策树。</font>具体方法是：从根节点开始，对节点计算所有可能的特征的信息增益，选择信息增益最大的特征作为节点的特征，由该特征的不同取值建立子节点；再对子节点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有特征可以选择为止。最后得到一个决策树。\n",
    "\n",
    "<font color='purple'>递归结束的条件是：程序遍历完所有的特征列，或者每个分支下的所有实例都具有相同的分类。</font>如果所有实例具有相同分类，则得到一个叶节点。任何到达叶节点的数据必然属于叶节点的分类，即叶节点里面必须是标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#嵌套模型\n",
    "\"\"\"\n",
    "函数功能：基于最大信息增益切分数据集，递归构建决策树\n",
    "参数说明：\n",
    "    dataSet：原始数据集（最后一列是标签）\n",
    "返回：\n",
    "    myTree：字典形式的树\n",
    "\"\"\"\n",
    "def createTree(dataSet):\n",
    "    #print(dataSet.columns) #列名Index(['no surfacing', 'flippers', 'fish'], dtype='object')\n",
    "    featlist = list(dataSet.columns) #提取出数据集所有的列    ['no surfacing', 'flippers', 'fish']\n",
    "    #print(featlist)\n",
    "    classlist = dataSet.iloc[:,-1].value_counts() #获取最后一列类标签   注：value_counts() 默认数值递减\n",
    "    #print(classlist.index[0])\n",
    "    #判断最多标签数目是否等于数据集行数，或者数据集是否只有一列 (极端情况)\n",
    "    if classlist[0]==dataSet.shape[0] or dataSet.shape[1] == 1:\n",
    "        return classlist.index[0] #如果是，返回类标签\n",
    "    axis = bestSplit(dataSet) #确定出当前最佳切分列的索引\n",
    "    bestfeat = featlist[axis] #获取该索引对应的特征,\n",
    "    myTree = {bestfeat:{}} #采用字典嵌套的方式存储树信息\n",
    "    del featlist[axis] #删除当前特征\n",
    "    valuelist = set(dataSet.iloc[:,axis]) #提取最佳切分列所有属性值，变成字典形式\n",
    "    for value in valuelist: #对每一个属性值递归建树\n",
    "        myTree[bestfeat][value] = createTree(mySplit(dataSet,axis,value)) #去掉已经提取的这一列\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree = createTree(dataSet)\n",
    "myTree # {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.决策树的存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造决策树是很耗时的任务，即使处理很小的数据集，也要花费几秒的时间，如果数据集很大，将会耗费很多计算时间。因此为了节省时间，建好树之后立马将其保存，后续使用直接调用即可。          \n",
    "              \n",
    "我这边使用的是numpy里面的save()函数，它可以直接把字典形式的数据保存为.npy文件，调用的时候直接使用load()函数即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#树的存储\n",
    "np.save('myTree.npy',myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#树的读取\n",
    "read_myTree = np.load('myTree.npy').item()# np.load()加载出来的是array形式，可以利用item()将读出里边的内容\n",
    "read_myTree  # {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四. 使用决策树执行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：对一个测试实例进行分类\n",
    "参数说明：\n",
    "    inputTree：已经生成的决策树\n",
    "    labels：存储选择的最优特征标签\n",
    "    testVec：测试数据列表，顺序对应原数据集\n",
    "返回：\n",
    "    classLabel：分类结果\n",
    "\"\"\"\n",
    "def classify(inputTree,labels, testVec):\n",
    "    firstStr = next(iter(inputTree)) #获取决策树第一个节点\n",
    "    secondDict = inputTree[firstStr] #下一个字典\n",
    "    featIndex = labels.index(firstStr) #第一个节点所在列的索引\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]) == dict : #数据类型为字典(还有子树）\n",
    "                classLabel = classify(secondDict[key], labels, testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers', 'fish']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(dataSet.columns)\n",
    "labels#['no surfacing', 'flippers', 'fish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputTree = myTree\n",
    "inputTree#{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstStr = next(iter(inputTree))\n",
    "firstStr#'no surfacing'\n",
    " \n",
    "secondDict = inputTree[firstStr]\n",
    "secondDict#{0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}\n",
    "secondDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数功能：对测试集进行预测，并返回预测后的结果\n",
    "参数说明：\n",
    "    train：训练集\n",
    "    test：测试集\n",
    "返回：\n",
    "    test：预测好分类的测试集\n",
    "\"\"\"\n",
    "def acc_classify(train,test):\n",
    "    inputTree = createTree(train) #根据测试集生成一棵树\n",
    "    labels = list(train.columns) #数据集所有的列名称\n",
    "    result = []\n",
    "    for i in range(test.shape[0]): #对测试集中每一条数据进行循环\n",
    "        testVec = test.iloc[i,:-1] #测试集中的一个实例\n",
    "        classLabel = classify(inputTree,labels,testVec) #预测该实例的分类\n",
    "        result.append(classLabel) #将分类结果追加到result列表中\n",
    "    test['predict']=result #将预测结果追加到测试集最后一列\n",
    "    acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean() #计算准确率    .mean()用于求平均值\n",
    "    print(f'模型预测准确率为{acc}')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish\n",
       "0             1         1  yes\n",
       "1             1         1  yes\n",
       "2             1         0   no\n",
       "3             0         1   no\n",
       "4             0         1   no"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataSet\n",
    "test = dataSet.iloc[:3,:]\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率为1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Florian_Gao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish predict\n",
       "0             1         1  yes     yes\n",
       "1             1         1  yes     yes\n",
       "2             1         0   no      no"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_classify(train,test)#模型预测准确率为1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用SKlearn中graphviz包实现决策树的绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相应的包\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征\n",
    "Xtrain = dataSet.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers\n",
       "0             1         1\n",
       "1             1         1\n",
       "2             1         0\n",
       "3             0         1\n",
       "4             0         1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签\n",
    "Ytrain = dataSet.iloc[:,-1]\n",
    "labels = Ytrain.unique().tolist()  #numpy中unique去除重复的单元数字 tolist()方法将数组或者矩阵转换成列表\n",
    " \n",
    "#注：sklearn要求特征为数字，所以需要把yes，no等转换为数字\n",
    "Ytrain = Ytrain.apply(lambda x: labels.index(x)) #用索引进行数字替换，这样就将文本转换为数字 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: fish, dtype: int64\n",
      "['yes', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过训练，我们可以使用 export_graphviz 导出器以 Graphviz 格式导出决策树. 如果你是用 conda 来管理包，那么安装 graphviz 二进制文件和 python 包可以用以下指令安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-9553e88b49b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#绘制树模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    " \n",
    "#绘制树模型\n",
    "tree.export_graphviz(clf)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#给图形增加标签和颜色\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=['no surfacing', 'flippers'],\n",
    "                                class_names=['fish', 'not fish'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graphviz.Source(dot_data)\n",
    "#sklearn利用的是cart，指标为基尼系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用render方法生成图形\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"fish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Florian_Gao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log2\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12104d748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "#mpl.matplotlib_fname()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "x=np.linspace(0,1,100)\n",
    "y=-np.log2(x)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `linspace` not found.\n"
     ]
    }
   ],
   "source": [
    "linspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
